name: Connectors up-to-date
concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

on:
  schedule:
    # Runs everyday Saturday at 12:00 UTC
    - cron: "0 12 * * 6"
  workflow_dispatch:
    inputs:
      connectors-options:
        description: "Options to pass to the 'airbyte-ci connectors' command group."
        default: '--language=python --language=low-code --language=manifest-only --metadata-query="''-rc.'' not in data.dockerImageTag" --metadata-query="''source-declarative-manifest'' not in data.dockerRepository"'
      auto-merge:
        description: "Whether to auto-merge the PRs created by the action."
        default: "false"
jobs:
  select_for_up_to_date:
    name: Select connectors for up-to-date
    runs-on: ubuntu-latest
    outputs:
      connector_matrix: ${{ steps.set_matrix.outputs.connector_matrix }}
    steps:
      - name: Checkout Airbyte
        uses: actions/checkout@v4
      - name: Select connectors for up-to-date [WORKFLOW]
        if: github.event_name == 'workflow_dispatch'
        uses: ./.github/actions/run-airbyte-ci
        with:
          context: "master"
          docker_hub_password: ${{ secrets.DOCKER_HUB_PASSWORD }}
          docker_hub_username: ${{ secrets.DOCKER_HUB_USERNAME }}
          gcp_gsm_credentials: ${{ secrets.GCP_GSM_CREDENTIALS }}
          gcs_credentials: ${{ secrets.METADATA_SERVICE_PROD_GCS_CREDENTIALS }}
          github_token: ${{ secrets.GH_PAT_MAINTENANCE_OSS }}
          sentry_dsn: ${{ secrets.SENTRY_AIRBYTE_CI_DSN }}
          s3_build_cache_access_key_id: ${{ secrets.SELF_RUNNER_AWS_ACCESS_KEY_ID }}
          s3_build_cache_secret_key: ${{ secrets.SELF_RUNNER_AWS_SECRET_ACCESS_KEY }}
          subcommand: "connectors ${{ github.event.inputs.connectors-options }} list --output-file=selected_connectors.json"
      
      - name: Select connectors for up-to-date [SCHEDULE]
        if: github.event_name == 'schedule'
        uses: ./.github/actions/run-airbyte-ci
        with:
          context: "master"
          docker_hub_password: ${{ secrets.DOCKER_HUB_PASSWORD }}
          docker_hub_username: ${{ secrets.DOCKER_HUB_USERNAME }}
          gcp_gsm_credentials: ${{ secrets.GCP_GSM_CREDENTIALS }}
          gcs_credentials: ${{ secrets.METADATA_SERVICE_PROD_GCS_CREDENTIALS }}
          github_token: ${{ secrets.GH_PAT_MAINTENANCE_OSS }}
          sentry_dsn: ${{ secrets.SENTRY_AIRBYTE_CI_DSN }}
          s3_build_cache_access_key_id: ${{ secrets.SELF_RUNNER_AWS_ACCESS_KEY_ID }}
          s3_build_cache_secret_key: ${{ secrets.SELF_RUNNER_AWS_SECRET_ACCESS_KEY }}
          subcommand: 'connectors --language=python --language=low-code --support-level=community --support-level=certified --metadata-query="\"source-declarative-manifest\" not in data.dockerRepository"  --metadata-query="\"-rc.\" not in data.dockerImageTag" list --output-file=selected_connectors.json'
          
      - name: Create the matrix by splitting the list of connectors into chunks of 50
        shell: python
        run: |
          import os 
          import json
          from pathlib import Path

          selected_connectors = json.loads(Path('selected_connectors.json').read_text())
          names = [f"--name={c['name']}" for c in selected_connectors]
          chunks = [names[i:i+50] for i in range(0, len(names), 50)]
          matrix = json.dumps({"include": [{"connector_names": " ".join(chunk)} for chunk in chunks]})
          Path("matrix.json").write_text(matrix)
      - name: Set matrix output
        id: set_matrix
        shell: bash
        run: echo "connector_matrix=$(cat matrix.json)" >> $GITHUB_OUTPUT

  connectors_up_to_date:
    needs: select_for_up_to_date
    name: Connectors up-to-date
    runs-on: connector-nightly-xlarge
    strategy:
      matrix: ${{ fromJson(needs.select_for_up_to_date.outputs.connector_matrix) }}
    permissions:
      pull-requests: write
    steps:
      - name: Checkout Airbyte
        uses: actions/checkout@v4
      - name: Run airbyte-ci connectors up-to-date [WORKFLOW]
        id: airbyte-ci-connectors-up-to-date-workflow-dispatch
        uses: ./.github/actions/run-airbyte-ci
        with:
          context: "master"
          dagger_cloud_token: ${{ secrets.DAGGER_CLOUD_TOKEN_CACHE_3 }}
          docker_hub_password: ${{ secrets.DOCKER_HUB_PASSWORD }}
          docker_hub_username: ${{ secrets.DOCKER_HUB_USERNAME }}
          gcp_gsm_credentials: ${{ secrets.GCP_GSM_CREDENTIALS }}
          gcs_credentials: ${{ secrets.METADATA_SERVICE_PROD_GCS_CREDENTIALS }}
          github_token: ${{ secrets.GH_PAT_MAINTENANCE_OSS }}
          sentry_dsn: ${{ secrets.SENTRY_AIRBYTE_CI_DSN }}
          s3_build_cache_access_key_id: ${{ secrets.SELF_RUNNER_AWS_ACCESS_KEY_ID }}
          s3_build_cache_secret_key: ${{ secrets.SELF_RUNNER_AWS_SECRET_ACCESS_KEY }}
          subcommand: "connectors --concurrency=10 ${{ matrix.connector_names}} up-to-date  --create-prs ${{ github.event.inputs.auto-merge == 'false' && '' || '--auto-merge' }}"

